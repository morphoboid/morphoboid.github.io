<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>MorphoBoid</title>

    <meta name="description" content="Pulseadmin - A clean, responsive HTML template">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">

    <link rel="stylesheet" href="css/normalize-and-boilerplate.css" />
    <link rel="stylesheet" href="css/font-awesome.css" />
    <link rel="stylesheet" href="css/flexslider.css" />
    <link rel="stylesheet" href="css/style.css" />

    <link href='http://fonts.googleapis.com/css?family=Bree+Serif|Pacifico' rel='stylesheet' type='text/css' />

    <script src="js/vendor/modernizr-2.6.2-respond-1.1.0.min.js"></script>
  </head>
  <body>


    <!-- start: off canvas area -->
    <aside class="off-canvas">
      <div class="row">
        <div class="columns col-17">
          <nav class="main-nav">
            <ul>
              <li><a class="current" href="index.html">Home</a></li>
              <li><a href="about.html">About us</a></li>
              <li><a href="projects.html">Projects</a></li>
              <li><a href="publications.html">Publications</a></li>
              <li><a href="contact.html">Contact</a></li>
            </ul>
          </nav>
        </div>
        <div class="columns col-12">
          <div class="social-links">
            <a href="#" title="Like us on Facebook">
              <i class="fa fa-facebook"></i>
            </a>
            <a href="#" title="Follow us on Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </div>
        </div>        
      </div>
    </aside>
    <!-- end: off canvas area -->

    <!-- start: ON canvas area -->
    <div class="on-canvas">
      <div class="canvas-overlay"></div>

      <header class="header">
        <div class="row max-inner">
          <div class="columns col-3">
            <a href="#" class="toggle-off-canvas"><i class="fa fa-bars"></i></a>
            <a href="index.html" class="logo">
              <img src="images/logo.png" alt="logo" />
               <!--<span class="highlight-color">Morpho</span>Boid-->
            </a>
          </div>
          <div class="columns col-7" style="width:700px">
            <nav class="main-nav">
              <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html">About us</a></li>
                <li><a href="projects.html">Projects</a></li>
                <li><a class="current" href="publications.html">Publications</a></li>
                <li><a href="contact.html">Contact</a></li>
              </ul>
            </nav>
          </div>
          <div class="columns col-2" style="width:150px">
            <div class="social-links">
              <a href="#" title="Like us on Facebook">
                <i class="fa fa-facebook"></i>
              </a>
              <a href="#" title="Follow us on Twitter">
                <i class="fa fa-twitter"></i>
              </a>
            </div>
          </div>
        </div>
      </header>

      <div class="main">
        <div class="max-inner">
          <div class="row">
            <div class="columns col-12">
              <header class="section-heading">
                <h2>Publications</h2>
                 <!--<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>-->
              </header>
            </div>
          </div>
          <div class="row">
            <div class="columns col-12 faqs"> 
              <!-- start: Question+Answer -->
              <div class="faq" id="heritagepubs">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>                        
                      <a href="#">
                        <i class="fa fa-chevron-right"></i>                        
                        Heritage Image Classification by Convolution Neural Networks<br/>
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Manh Tu VU, Marie BEURTON-AIMAR, Van Linh LE  <br/>
                        1st International Conference on Multimedia Analysis and Pattern Recognition, 2018 (MAPR - 2018)</strong>
                      </a>
                    </strong>                    
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Manh Tu VU, Marie BEURTON-AIMAR, Van Linh LE (MAPR - 2018 accepted)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    In this project, we have explored the use of Convolution Neural Networks for semantic
classification of heritage images. Recently four
architectures, AlexNet, GoogLeNet, ResNet, and SENet have been proposed. We have tested them with two different learning modalities. Besides conventional training from scratch, we have resorted to pre-trained networks that are fine-tuned
on a huge amount of data in order to avoid overfitting problems and to
reduce design/computing time. Experiments on a dataset we built by ourselves from Heritage repository show that with the
help of this step of fine-tuning, one of the simplest (and oldest) networks
AlexNet is able to produce similar results than most sophisticated ones as ResNet which is pretty 3 times more consuming in computing time,
mainly due to the number of the layer it uses. With this model, we
have been able to show that our model can classify in the right way
more than 98% of the images belonging to the dataset test. From
now, this model can be used to classify the full data set of the
Heritage repository.
                  </p>
                  <p><a href="#">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->
              <!-- start: Question+Answer -->
              <div class="faq" id="devmappubs">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <i class="fa fa-chevron-right"></i>
                         Automated morphometrics using deep neural networks: a case study on a beneficial insect species <br/>
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY <br/>
                        10th Symposium National de Morphometrie et Evolution des Formes (SMEF), 2018 (SMEF-18)</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY (ICPRS - 2018 accepted)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    Morphometry landmarks are used in many biological applications. Mostly, the landmarks are defined manually or semi-automatically by applying the image processing techniques. In recent years, deep learning is known as a good solution to achieve image analysis tasks. It appears in many fields such as classification, recognition, face detection. In this context, we present a convolutional neural network to predict the landmarks on 2D biological images, specifically beetles images. The proposed model is designed from an elementary block of three layers: convolution, pooling, and dropout. The experiments on the proposed network have been done in two steps: training from scratch and fine-tuning from a trained model. The dataset includes the images of collecting from 293 beetles (on head, pronotum, body parts). Among these, a set of manual landmarks has been built for each part by the biologists. In this work, we have worked on prediction of pronotum landmarks. The quality of predicted landmarks is evaluated by calculating the distance in pixels between the coordinates of the predicted landmarks and manual landmarks which are considered as ground truth. 
                  </p>
                  <p><a href="#">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->
              <!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <i class="fa fa-chevron-right"></i>
                         Towards landmarks prediction with Deep Network<br/>
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY <br/>
                        9th International Conference on Pattern Recognition Systems, 2018 (ICPRS-18)</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY (ICPRS - 2018 accepted)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    Morphometry landmarks are used in many biological applications. Mostly, the landmarks are defined manually or semi-automatically by applying the image processing techniques. In recent years, deep learning is known as a good solution to achieve image analysis tasks. It appears in many fields such as classification, recognition, face detection. In this context, we present a convolutional neural network to predict the landmarks on 2D biological images, specifically beetles images. The proposed model is designed from an elementary block of three layers: convolution, pooling, and dropout. The experiments on the proposed network have been done in two steps: training from scratch and fine-tuning from a trained model. The dataset includes the images of collecting from 293 beetles (on head, pronotum, body parts). Among these, a set of manual landmarks has been built for each part by the biologists. In this work, we have worked on prediction of pronotum landmarks. The quality of predicted landmarks is evaluated by calculating the distance in pixels between the coordinates of the predicted landmarks and manual landmarks which are considered as ground truth. 
                  </p>
                  <p><a href="#">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->
              <!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <i class="fa fa-chevron-right"></i>
                        Landmarks detection by applying Deep networks<br/>
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY <br/>
                        1st International Conference on Multimedia Analysis and Pattern Recognition, 2018 (MAPR - 2018)</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY (MAPR - 2018 accepted)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    Morphometric analysis is a general method applied to organisms and used to appreciate the covariances between the ecological factors and the organisms (shape, size, form,...) in which, landmark-based morphometry is known as one of the approaches to analyze the characteristics of organisms. Finding landmarks setting can give to biologists a comprehensive description of the organism. In this study, we propose a convolutional neural network (CNN) to predict the landmarks on beetle images. The network is designed as a pipeline of layers, it has been trained with a set of manually labeled landmarks dataset. Then, the network has been used to provide the morphometric landmarks on biological images automatically. The coordinates of predicted landmarks have been evaluated by computing their distance to the manual coordinates given by the biologists. Besides, the average of distance errors on each landmark has been also computed. The network model is implemented by Python on Lasagne framework.
                  </p>
                  <p><a href="#">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->
              <!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <i class="fa fa-chevron-right"></i>
                        MAELab: a framework to automatize landmark estimation <br/>
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Adrien KRAHENBUHL, Nicolas PARISEY <br/>
                        International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, 2017 (WSCG-17)</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Adrien KRAHENBUHL, Nicolas PARISEY (WSCG - 2017)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    In biology, the morphometric analysis is widely used to analyze the inter-organisms variations. It allows to classify and to determine the evolution of an organism’s family. The morphometric methods consider features such as shape, structure, color, or size of the studied objects. In previous works [8], we have analyzed beetle mandibles by using the centroid as feature, in order to classify the beetles. We have shown that the Probabilistic Hough Transform (PHT) is an efficient unsupervised method to compute the centroid. This paper proposes a new approach to precisely estimate the landmark geometry, points of interest defined by biologists on the mandible contours. In order to automatically register the landmarks on different mandibles, we defined patches around manual landmarks of the reference image. Each patch is described by computing its SIFT descriptor. Considering a query image, we apply a registration step performed by an Iterative Principal Component Analysis which identify the rotation and translation parameters. Then, the patches in the query image are identified and the SIFT descriptors computed. The biologists have collected 293 beetles to provide two sets of mandible images separated into left and right side. The experiments show that, depending on the position of the landmarks on the mandible contour, the performance can go up to 98% of good detection. The complete workflow is implemented in the MAELab framework, freely available as library on GitHub.
                  </p>
                  <p><a href="uploads/papers/M71_full.pdf">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->  

              <!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <i class="fa fa-chevron-right"></i>
                        SIFT descriptor to set landmarks on biological images<br/>
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Adrien KRAHENBUHL, Nicolas PARISEY <br/>
                        GRETSI, 2017</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-5">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Adrien KRAHENBUHL, Nicolas PARISEY (GRETSI - 2017)</p>-->
                 <p style="text-align: justify"><b>Abstract:</b>
                    Image analysis is a large field in image processing and it has applied in practice with many application in the different majors such as medicine, computer vision, biology, ... In biology, images are widely used for a long time, to study molecule structures or behaviors, tissues characteristics and in general to measure and to classify anatomical details. Classification of biological samples can be obtained from studying morphological features but at this time, setting morphological markers is done manually. In this work, we have focused on the problem to replace manual operations by automatic procedures to set landmarks which are point of interests in biological images. This paper presents how we have designed a specific way to use the SIFT descriptor to improve the results that we have obtained before to achieve this task. The two main characteristics of our method are the reduction of the patch area to compute de source descriptor and the definition of a restrictive search area of the target. The efficiency of the method is evaluated on two set of images: left and right mandibles of beetles belonging to a study of the national institute of agriculture (INRA). The complete method is implemented in a framework called MAELab and freely available on GitHub.
                  </p>
                   <p><a href="uploads/papers/SIFT_landmarks.pdf">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->  

<!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <i class="fa fa-chevron-right"></i>
                        Estimating landmarks on 2D images of beetle mandibles<br/>
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">LE Van Linh, BEURTON-AIMAR Marie, SALMON Jean-Pierre, ALEXIA Marie, PARISEY Nicolas <br/>
                        International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, 2015 (WSCG-15)</strong>
                      </a>
                    </strong>
                  </div>
                  
                </div>
                <div class="faq-a">
                  <!--<p>LE Van Linh, BEURTON-AIMAR Marie, SALMON Jean-Pierre, ALEXIA Marie, PARISEY Nicolas (WSCG - 2015)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    Studying links between phenotype/genotype and agricultural practices is one of the main current topics in agro-
nomical research. Phenotypes is the observable physical characteristics of an organism like its age, sex and more,
often extracted with the help of image analysis of its morphology. Nowadays, getting good quality of images for
numerous individuals is easy but that leads to design automatic procedures to replace manual exploration of such
amount of data. Several bottlenecks have been identified to analyze automatically images. One of them is segmen-
tation of selected area and/or shapes, another well-known one is setting automatically morphometric landmarks.
Landmarks are points on the object which can be used to identify or to classify the objects.
It exists a lot of methods to experiment landmark setting, depending on the image contents. The described work
has been initiated by using the article of Palaniswamy et al.
"Automatic identification of landmarks in digital im-
ages". They proposed a method based on calculus of a Probabilistic Hough Transform coupled to a template
matching algorithm. They applied their method to the Drosophilia wings. In our study, we got a set of 291 beetles
. For each one, 2D images of 5 different parts of their anatomy have been taken: mandibles left and right, head,
pronotum and elytra. The first part of the project was to test how the Palaniswamy’s method could be used to
analyze them. We have implemented all the required algorithms to compute positions of mandibles landmarks and
compared the obtained results to landmarks which have been manually set by biologists. We will see that if we use
centroid size to characterize mandibles, the size computed from automatic landmarks is close to the one computed
from manual ones. Future works will focus on definition of a semi-landmarks procedure which would add some
features as the measure of the curve between two landmarks.
                  </p>
                   <p><a href="uploads/papers/E73_full.pdf">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer --> 


            </div>
          </div>
<!--
          <div class="row">
            <div class="columns col-12">
              <h2>Ask about a solution</h2>
              <form class="contact-form">
                <div class="row">
                  <div class="columns col-5 no-left-pad">
                    <div class="row">
                      <div class="columns col-3 no-left-pad"><label for="name" class="inline-label">Name:</label></div>
                      <div class="columns col-9"><input placeholder="Brian Jones" type="text" /></div>
                    </div>

                    <div class="columns col-3 no-left-pad"><label for="email" class="inline-label">Email:</label></div>
                    <div class="columns col-9"><input placeholder="b_jones@gmail.com" type="email" /></div>
                  </div>
                  <div class="columns col-7 no-right-pad">
                    <textarea placeholder="Message&hellip;" rows="4"></textarea>
                    <input type="submit" value="Send message" class="submit float-right">
                  </div>
                </div>
              </form>
            </div>
          </div>

-->
        </div>
      </div>

      <footer class="footer">
        <div class="row">
          <div class="max-inner footer-content">
            <div class="columns col-3">
              <h3>Contact</h3>
              <p>
                MorphoBoid team<br />
                LaBRI laboratory<br />
                351 cours de la Liberation<br />
                Talence - 33400, France
                <br />
                Phone: +33(0)5 4000 69 00<br />
              </p>
            </div>
            <div class="columns col-3">
              <h3>Probjects</h3>
              <ul>
                <li><a href="projects.html">DevMAP project</a></li>
                <li><a href="projects.html">Heritage classification</a></li>
                <li><a href="projects.html">GESHAEM project</a></li>
                <li><a href="projects.html">ADDICTO project</a></li>
              </ul>
            </div>
            <div class="columns col-3">
              <h3>Positions</h3>
              <ul>
                <li><a href="#">Engineer position</a></li>
                <li><a href="#">Internship position</a></li>
                <li><a href="#">Phd thesis position</a></li>
                <li><a href="#">Post-doct position</a></li>
              </ul>
            </div>
            <div class="columns col-3">
              <h3>Support</h3>
              <p>
                MorphoBoid team
                <br />
              </p>
            </div>
          </div>
        </div>

        <div class="row copyright">
          <div class="max-inner">
            <div class="row">
              <div class="columns col-12">
                <p>Copyright &copy; 2018 morphoboid. All rights reserved.</p>
              </div>
            </div>
          </div>
        </div>
      </footer>

    </div>
    <!-- end: ON canvas area -->


    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.js"></script>
    <script>window.jQuery || document.write('<script src="js/vendor/jquery-1.10.1.js"><\/script>')</script>

    <script src="js/plugins.js"></script>
    <script src="js/main.js"></script>

    <script>
      var _gaq=[['_setAccount','UA-XXXXX-X'],['_trackPageview']];
      (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
      g.src='//www.google-analytics.com/ga.js';
      s.parentNode.insertBefore(g,s)}(document,'script'));
    </script>
  </body>
</html>
