<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>MorphoBoid</title>

    <meta name="description" content="Pulseadmin - A clean, responsive HTML template">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">

    <link rel="stylesheet" href="css/normalize-and-boilerplate.css" />
    <link rel="stylesheet" href="css/font-awesome.css" />
    <link rel="stylesheet" href="css/flexslider.css" />
    <link rel="stylesheet" href="css/style.css" />

    <link href='http://fonts.googleapis.com/css?family=Bree+Serif|Pacifico' rel='stylesheet' type='text/css' />

    <script src="js/vendor/modernizr-2.6.2-respond-1.1.0.min.js"></script>
  </head>
  <body>


    <!-- start: off canvas area -->
    <aside class="off-canvas">
      <div class="row">
        <div class="columns col-17">
          <nav class="main-nav">
            <ul>
              <li><a class="current" href="index.html">Home</a></li>              
              <li><a href="projects.html">Projects</a></li>
              <li><a href="publications.html">Publications</a></li>
                <li><a href="about.html">Peoples</a></li>
              <li><a href="contact.html">Contact</a></li>
            </ul>
          </nav>
        </div>
        <div class="columns col-12">
          <div class="social-links">
            <a href="#" title="Like us on Facebook">
              <i class="fa fa-facebook"></i>
            </a>
            <a href="#" title="Follow us on Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </div>
        </div>        
      </div>
    </aside>
    <!-- end: off canvas area -->

    <!-- start: ON canvas area -->
    <div class="on-canvas">
      <div class="canvas-overlay"></div>

      <header class="header">
        <div class="row max-inner">
          <div class="columns col-3">
            <a href="#" class="toggle-off-canvas"><i class="fa fa-bars"></i></a>
            <a href="index.html" class="logo">
              <img src="images/logo.png" alt="logo" />
               <!--<span class="highlight-color">Morpho</span>Boid-->
            </a>
          </div>
          <div class="columns col-7" style="width:700px">
            <nav class="main-nav">
              <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="projects.html">Projects</a></li>
                <li><a class="current" href="publications.html">Publications</a></li>
                <li><a href="about.html">Peoples</a></li>
                <li><a href="contact.html">Contact</a></li>
              </ul>
            </nav>
          </div>
          <div class="columns col-2" style="width:150px">
            <div class="social-links">
              <a href="http://www.labri.fr/" target = "_blank" title="LaBRI" style = "border:none;border-radius:0;width:40px">
                <!--<i class="fa fa-facebook"></i>-->
                <img src = 'images/labri.png' alt="labri" />
              </a>
              <a href="https://www.u-bordeaux.fr/" target="_blank" title="U-Bordeaux" style = "border:none;border-radius:0;width:60px">
                <img src = 'images/u_bordeaux.jpg' alt="ubordeaux" />
                <!--<i class="fa fa-twitter"></i>-->
              </a>
            </div>
          </div>
        </div>
      </header>

      <div class="main">
        <div class="max-inner">
          <div class="row">
            <div class="columns col-12">
              <header class="section-heading" style="padding: 0px">
                <br>
                <h2>Publications</h2>
                 <!--<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>-->
              </header>
            </div>
          </div>
          <div class="row">
            <div class="columns col-12 faqs">  
              <!-- start: Question+Answer -->
              <div class="faq" id="devmappubs">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Pirrone, Antoine, Marie Beurton Aimar, and Nicholas Journet, </strong>
                        <i class="fa fa-chevron-right"></i>
                         Papy-S-Net: A Siamese Network to match papyrus fragments<strong style ="font-weight:normal; color:#8a908d; font-size: 16px">, Proceedings of the 5th International Workshop on Historical Document Imaging and Processing (HIP), 2019</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <p style="text-align: justify"><b>Abstract:</b>
                      Like all heritage documents, papyri are the subject of an in-depth study by scientists. While large volumes of papyri have been digi-
tized and indexed, many are still waiting to be so. It takes time to study a papyrus mainly because they are rarely available in one
piece. Papyrologists must review a large number of fragments, find those that go together and then assemble them to finally analyze the
text. Unfortunately, some fragments no longer exist. It is then a time consuming puzzle to solve, where not all the pieces are available
and where fragments boundaries are not perfectly matching. This article describes a method to help Papyrologists save time by helping them to solve this complex puzzle. We provide a solu-
tion where an expert use a fragment as a request element and get fragments that belong to the same papyrus. The main contribution is the proposal of a deep siamese network architecture, called Papy-S-Net for Papyrus-Siamese-Network, designed for papyri fragment matching. This network is trained and validated on
500 papyrus fragments approx. We compare the results of Papy-S-Net with a previous work which proposes a siamese
network to match written symbols. In order to train and validate the network, we proceed to the extraction of patches from the papyrus
fragments to create our ground truth. Papy-S-Net outperforms Koch et al.’s network. We also evaluate our approach on a real use case on which
Papy-S-Net achieves 79% of correct matches.
                  </p>
                  <p><a href="https://hal.archives-ouvertes.fr/hal-02367779/document" target="_blank">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->

              <!-- start: Question+Answer -->
              <div class="faq" id="devmappubs">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Cecilia Ostertag, Marie Beurton-Aimar, Thierry Urruty, </strong>
                        <i class="fa fa-chevron-right"></i>
                         3D-SiameseNet to Analyze Brain MRI<strong style ="font-weight:normal; color:#8a908d; font-size: 16px">, 10th International Conference on Pattern Recognition Systems (ICPRS), 2019 (ICPRS-19)</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <p style="text-align: justify"><b>Abstract:</b>
                     Prediction of the cognitive evolution of a person susceptible to develop a neurodegenerative disorder is crucial to provide an appropriate treatment as soon as possible. In this paper we propose a 3D siamese network designed to extract features from whole-brain 3D MRI images. We show that it is possible to extract meaningful features using convolution layers, reducing the need of classical image processing operations such as segmentation or pre-computing features such as cortical thickness. To lead this study we used the Alzheimer's Disease Neuroimaging Initiative (ADNI), a public data base of 3D MRI brain images. A set of 247 subjects has been extracted, all of the subjects having 2 images in a range of 12 months. In order to measure the evolution of the patients states we have compared these 2 images. Our work has been inspired at the beginning by an article of Bhagwat et al. in 2018, who have proposed a siamese network to predict the status of patients but without any convolutional layers and reducing the MRI images to a vector of features extracted from predefined ROIs. We show that our network achieves an accuracy of 90\% in the classification of cognitively declining VS stable patients. This result has been obtained without the help of a cognitive score and with a small number of patients comparing to the current datasets size claimed in deep learning domain. 
                  </p>
                  <p><a href="https://arxiv.org/abs/1909.01098" target="_blank">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->
             
              <!-- start: Question+Answer -->
              <div class="faq" id="devmappubs">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY, </strong>
                        <i class="fa fa-chevron-right"></i>
                         Automated morphometrics using deep neural networks: a case study on a beneficial insect species<strong style ="font-weight:normal; color:#8a908d; font-size: 16px">, 10th Symposium National de Morphometrie et Evolution des Formes (SMEF), 2018 (SMEF-18)</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY (ICPRS - 2018 accepted)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    Morphometry landmarks are used in many biological applications. Mostly, the landmarks are defined manually or semi-automatically by applying the image processing techniques. In recent years, deep learning is known as a good solution to achieve image analysis tasks. It appears in many fields such as classification, recognition, face detection. In this context, we present a convolutional neural network to predict the landmarks on 2D biological images, specifically beetles images. The proposed model is designed from an elementary block of three layers: convolution, pooling, and dropout. The experiments on the proposed network have been done in two steps: training from scratch and fine-tuning from a trained model. The dataset includes the images of collecting from 293 beetles (on head, pronotum, body parts). Among these, a set of manual landmarks has been built for each part by the biologists. In this work, we have worked on prediction of pronotum landmarks. The quality of predicted landmarks is evaluated by calculating the distance in pixels between the coordinates of the predicted landmarks and manual landmarks which are considered as ground truth. 
                  </p>
                  <p><a href="#" target="_blank">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->
              <!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY, </strong>
                        <i class="fa fa-chevron-right"></i>
                         Towards landmarks prediction with Deep Network<strong style ="font-weight:normal; color:#8a908d; font-size: 16px">, 9th International Conference on Pattern Recognition Systems, 2018 (ICPRS-18)</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY (ICPRS - 2018 accepted)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    Morphometry landmarks are used in many biological applications. Mostly, the landmarks are defined manually or semi-automatically by applying the image processing techniques. In recent years, deep learning is known as a good solution to achieve image analysis tasks. It appears in many fields such as classification, recognition, face detection. In this context, we present a convolutional neural network to predict the landmarks on 2D biological images, specifically beetles images. The proposed model is designed from an elementary block of three layers: convolution, pooling, and dropout. The experiments on the proposed network have been done in two steps: training from scratch and fine-tuning from a trained model. The dataset includes the images of collecting from 293 beetles (on head, pronotum, body parts). Among these, a set of manual landmarks has been built for each part by the biologists. In this work, we have worked on prediction of pronotum landmarks. The quality of predicted landmarks is evaluated by calculating the distance in pixels between the coordinates of the predicted landmarks and manual landmarks which are considered as ground truth. 
                  </p>
                  <p><a href="https://digital-library.theiet.org/content/conferences/10.1049/cp.2018.1291" target="_blank">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->
              <!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY, </strong>
                        <i class="fa fa-chevron-right"></i>
                        Landmarks detection by applying Deep networks<strong style ="font-weight:normal; color:#8a908d; font-size: 16px">, 1st International Conference on Multimedia Analysis and Pattern Recognition, 2018 (MAPR - 2018)</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Akka ZEMMARI, Nicolas PARISEY (MAPR - 2018 accepted)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    Morphometric analysis is a general method applied to organisms and used to appreciate the covariances between the ecological factors and the organisms (shape, size, form,...) in which, landmark-based morphometry is known as one of the approaches to analyze the characteristics of organisms. Finding landmarks setting can give to biologists a comprehensive description of the organism. In this study, we propose a convolutional neural network (CNN) to predict the landmarks on beetle images. The network is designed as a pipeline of layers, it has been trained with a set of manually labeled landmarks dataset. Then, the network has been used to provide the morphometric landmarks on biological images automatically. The coordinates of predicted landmarks have been evaluated by computing their distance to the manual coordinates given by the biologists. Besides, the average of distance errors on each landmark has been also computed. The network model is implemented by Python on Lasagne framework.
                  </p>
                  <p><a href="https://ieeexplore.ieee.org/abstract/document/8337519" target="_blank">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->
              <!-- start: Question+Answer -->
              <div class="faq" id="heritagepubs">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>                        
                      <a href="#">
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Manh Tu VU, Marie BEURTON-AIMAR, Van Linh LE,</strong>
                        <i class="fa fa-chevron-right"></i>                        
                        Heritage Image Classification by Convolution Neural Networks
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">, 1st International Conference on Multimedia Analysis and Pattern Recognition, 2018 (MAPR - 2018)</strong>
                      </a>
                    </strong>                    
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Manh Tu VU, Marie BEURTON-AIMAR, Van Linh LE (MAPR - 2018 accepted)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    In this project, we have explored the use of Convolution Neural Networks for semantic
classification of heritage images. Recently four
architectures, AlexNet, GoogLeNet, ResNet, and SENet have been proposed. We have tested them with two different learning modalities. Besides conventional training from scratch, we have resorted to pre-trained networks that are fine-tuned
on a huge amount of data in order to avoid overfitting problems and to
reduce design/computing time. Experiments on a dataset we built by ourselves from Heritage repository show that with the
help of this step of fine-tuning, one of the simplest (and oldest) networks
AlexNet is able to produce similar results than most sophisticated ones as ResNet which is pretty 3 times more consuming in computing time,
mainly due to the number of the layer it uses. With this model, we
have been able to show that our model can classify in the right way
more than 98% of the images belonging to the dataset test. From
now, this model can be used to classify the full data set of the
Heritage repository.
                  </p>
                  <p><a href="https://ieeexplore.ieee.org/document/8337517" target="_blank">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->
              <!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Adrien KRAHENBUHL, Nicolas PARISEY </strong>
                        <i class="fa fa-chevron-right"></i>
                        MAELab: a framework to automatize landmark estimation
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">, International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, 2017 (WSCG-17)</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-3">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Adrien KRAHENBUHL, Nicolas PARISEY (WSCG - 2017)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    In biology, the morphometric analysis is widely used to analyze the inter-organisms variations. It allows to classify and to determine the evolution of an organism’s family. The morphometric methods consider features such as shape, structure, color, or size of the studied objects. In previous works [8], we have analyzed beetle mandibles by using the centroid as feature, in order to classify the beetles. We have shown that the Probabilistic Hough Transform (PHT) is an efficient unsupervised method to compute the centroid. This paper proposes a new approach to precisely estimate the landmark geometry, points of interest defined by biologists on the mandible contours. In order to automatically register the landmarks on different mandibles, we defined patches around manual landmarks of the reference image. Each patch is described by computing its SIFT descriptor. Considering a query image, we apply a registration step performed by an Iterative Principal Component Analysis which identify the rotation and translation parameters. Then, the patches in the query image are identified and the SIFT descriptors computed. The biologists have collected 293 beetles to provide two sets of mandible images separated into left and right side. The experiments show that, depending on the position of the landmarks on the mandible contour, the performance can go up to 98% of good detection. The complete workflow is implemented in the MAELab framework, freely available as library on GitHub.
                  </p>
                  <p><a href="https://hal.archives-ouvertes.fr/hal-01571440/" target="_blank">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->  

              <!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">Van Linh LE, Marie BEURTON-AIMAR, Adrien KRAHENBUHL, Nicolas PARISEY, </strong>
                        <i class="fa fa-chevron-right"></i>
                        SIFT descriptor to set landmarks on biological images<strong style ="font-weight:normal; color:#8a908d; font-size: 16px">, GRETSI, 2017</strong>
                      </a>
                    </strong>
                  </div>
                  <!--<div class="columns col-2 float-right">
                    <div class="faq-rating stars-5">
                      <span></span><span></span><span></span><span></span><span></span>
                    </div>
                  </div>-->
                </div>
                <div class="faq-a">
                  <!--<p>Van Linh LE, Marie BEURTON-AIMAR, Adrien KRAHENBUHL, Nicolas PARISEY (GRETSI - 2017)</p>-->
                 <p style="text-align: justify"><b>Abstract:</b>
                    Image analysis is a large field in image processing and it has applied in practice with many application in the different majors such as medicine, computer vision, biology, ... In biology, images are widely used for a long time, to study molecule structures or behaviors, tissues characteristics and in general to measure and to classify anatomical details. Classification of biological samples can be obtained from studying morphological features but at this time, setting morphological markers is done manually. In this work, we have focused on the problem to replace manual operations by automatic procedures to set landmarks which are point of interests in biological images. This paper presents how we have designed a specific way to use the SIFT descriptor to improve the results that we have obtained before to achieve this task. The two main characteristics of our method are the reduction of the patch area to compute de source descriptor and the definition of a restrictive search area of the target. The efficiency of the method is evaluated on two set of images: left and right mandibles of beetles belonging to a study of the national institute of agriculture (INRA). The complete method is implemented in a framework called MAELab and freely available on GitHub.
                  </p>
                   <p><a href="uploads/papers/SIFT_landmarks.pdf" target="_blank">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer -->  

<!-- start: Question+Answer -->
              <div class="faq">
                <div class="row faq-q">
                  <div class="columns col-10">
                    <strong>
                      <a href="#">
                        <strong style ="font-weight:normal; color:#8a908d; font-size: 16px">LE Van Linh, BEURTON-AIMAR Marie, SALMON Jean-Pierre, ALEXIA Marie, PARISEY Nicolas, </strong>
                        <i class="fa fa-chevron-right"></i>
                        Estimating landmarks on 2D images of beetle mandibles<strong style ="font-weight:normal; color:#8a908d; font-size: 16px">, International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, 2015 (WSCG-15)</strong>
                      </a>
                    </strong>
                  </div>
                  
                </div>
                <div class="faq-a">
                  <!--<p>LE Van Linh, BEURTON-AIMAR Marie, SALMON Jean-Pierre, ALEXIA Marie, PARISEY Nicolas (WSCG - 2015)</p>-->
                  <p style="text-align: justify"><b>Abstract:</b>
                    Studying links between phenotype/genotype and agricultural practices is one of the main current topics in agro-
nomical research. Phenotypes is the observable physical characteristics of an organism like its age, sex and more,
often extracted with the help of image analysis of its morphology. Nowadays, getting good quality of images for
numerous individuals is easy but that leads to design automatic procedures to replace manual exploration of such
amount of data. Several bottlenecks have been identified to analyze automatically images. One of them is segmen-
tation of selected area and/or shapes, another well-known one is setting automatically morphometric landmarks.
Landmarks are points on the object which can be used to identify or to classify the objects.
It exists a lot of methods to experiment landmark setting, depending on the image contents. The described work
has been initiated by using the article of Palaniswamy et al.
"Automatic identification of landmarks in digital im-
ages". They proposed a method based on calculus of a Probabilistic Hough Transform coupled to a template
matching algorithm. They applied their method to the Drosophilia wings. In our study, we got a set of 291 beetles
. For each one, 2D images of 5 different parts of their anatomy have been taken: mandibles left and right, head,
pronotum and elytra. The first part of the project was to test how the Palaniswamy’s method could be used to
analyze them. We have implemented all the required algorithms to compute positions of mandibles landmarks and
compared the obtained results to landmarks which have been manually set by biologists. We will see that if we use
centroid size to characterize mandibles, the size computed from automatic landmarks is close to the one computed
from manual ones. Future works will focus on definition of a semi-landmarks procedure which would add some
features as the measure of the curve between two landmarks.
                  </p>
                   <p><a href="https://dspace5.zcu.cz/handle/11025/29598" target="_blank">PDF</a></p>
                </div>
              </div>  
              <!-- end: Question+Answer --> 


            </div>
          </div>
<!--
          <div class="row">
            <div class="columns col-12">
              <h2>Ask about a solution</h2>
              <form class="contact-form">
                <div class="row">
                  <div class="columns col-5 no-left-pad">
                    <div class="row">
                      <div class="columns col-3 no-left-pad"><label for="name" class="inline-label">Name:</label></div>
                      <div class="columns col-9"><input placeholder="Brian Jones" type="text" /></div>
                    </div>

                    <div class="columns col-3 no-left-pad"><label for="email" class="inline-label">Email:</label></div>
                    <div class="columns col-9"><input placeholder="b_jones@gmail.com" type="email" /></div>
                  </div>
                  <div class="columns col-7 no-right-pad">
                    <textarea placeholder="Message&hellip;" rows="4"></textarea>
                    <input type="submit" value="Send message" class="submit float-right">
                  </div>
                </div>
              </form>
            </div>
          </div>

-->
        </div>
      </div>

      <footer class="footer">
        <div class="row">
          <div class="max-inner footer-content">
            <div class="columns col-3">
              <h3>Contact</h3>
              <p>
                MorphoBoid team<br />
                LaBRI laboratory<br />
                351 cours de la Liberation<br />
                Talence - 33400, France
                <br />
                Phone: +33(0)5 4000 69 00<br />
              </p>
            </div>
            <div class="columns col-3">
              <h3>Probjects</h3>
              <ul>
                <li><a href="projects.html">DevMAP project</a></li>
                <li><a href="projects.html">Heritage classification</a></li>
                <li><a href="projects.html">GESHAEM project</a></li>
                <li><a href="projects.html">ADDICTO project</a></li>
              </ul>
            </div>
            <div class="columns col-3">
              <h3>Positions</h3>
              <ul>
                <li><a href="#">Engineer position</a></li>
                <li><a href="#">Internship position</a></li>
                <li><a href="#">Phd thesis position</a></li>
                <li><a href="#">Post-doct position</a></li>
              </ul>
            </div>
            <div class="columns col-3">
              <h3>Support</h3>
              <p>
                MorphoBoid team
                <br />
              </p>
            </div>
          </div>
        </div>

        <div class="row copyright">
          <div class="max-inner">
            <div class="row">
              <div class="columns col-12">
                <p>Copyright &copy; 2018 morphoboid. All rights reserved.</p>
              </div>
            </div>
          </div>
        </div>
      </footer>

    </div>
    <!-- end: ON canvas area -->


    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.js"></script>
    <script>window.jQuery || document.write('<script src="js/vendor/jquery-1.10.1.js"><\/script>')</script>

    <script src="js/plugins.js"></script>
    <script src="js/main.js"></script>

    <script>
      var _gaq=[['_setAccount','UA-XXXXX-X'],['_trackPageview']];
      (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
      g.src='//www.google-analytics.com/ga.js';
      s.parentNode.insertBefore(g,s)}(document,'script'));
    </script>
  </body>
</html>
